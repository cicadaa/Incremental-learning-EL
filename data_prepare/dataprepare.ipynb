{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.4"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "pythonjvsc74a57bd025747ecf440d9432ac99c9b9e9b6da36a532ce26e5114e1515f71dad76afa3ba",
   "display_name": "Python 3.8.4 64-bit ('thesis01': virtualenvwrapper)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from datetime import date, timedelta\n",
    "from functools import reduce\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import DataFrame\n",
    "from pyspark.sql.functions import lpad, concat, col, lit, to_timestamp, udf, create_map\n",
    "from pyspark.sql.types import IntegerType\n",
    "from itertools import chain\n",
    "import pandas as pd\n",
    "import os\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rename columns\n",
    "def renameDataframe(df):\n",
    "    df = df.withColumnRenamed(\"Time-Kvarter\",\"Time\") \\\n",
    "        .withColumnRenamed(\"MålerVærdier\", \"MeterValue\") \\\n",
    "        .withColumnRenamed(\"MålerEgenskab\", \"MeterType\") \\\n",
    "        .withColumnRenamed(\"MålerArtBeskrivelse\", \"MeterDescribe\") \n",
    "    return df\n",
    "\n",
    "#preprocess dataframe\n",
    "def processDataframe(df):\n",
    "    df = df.withColumn(\"MålerVærdier\", df[\"MålerVærdier\"].cast(\"float\")) \\\n",
    "        .withColumn(\"Time-Kvarter\", lpad(df['Time-Kvarter'],4,'0')) \\\n",
    "        .withColumn('Datetime', concat(col('Dato'),lit('-'),col('Time-Kvarter'))) \\\n",
    "        .withColumn('FullAdresses', concat(col('InstallationAdresse'),lit(' '),col('InstallationPostNr'))) \\\n",
    "        .withColumn(\"Datetime\", to_timestamp(\"Datetime\", \"yyyy-MM-dd-HHmm\")) \\\n",
    "        .withColumn(\"Dato\", to_timestamp(\"Dato\", \"yyyy-MM-dd\")) \n",
    "    # df = df.drop(\"Dato\")\n",
    "    df = df.drop(\"Dataset\")\n",
    "    df = df.drop(\"InstallationAdresse\")\n",
    "    df = df.drop(\"InstallationPostNr\")\n",
    "    df = df.drop(\"MeterRegister\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#init spark app\n",
    "spark = SparkSession.builder \\\n",
    "            .master(\"local\") \\\n",
    "            .appName(\"Tref\") \\\n",
    "            .config(\"spark.executor.memory\", \"4g\") \\\n",
    "            .getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean parquet and store as csv\n",
    "path = 'data/2020/monthly/'\n",
    "files = os.listdir(path)\n",
    "\n",
    "with open('data/address500.json') as f:\n",
    "    addressList = json.load(f)\n",
    "\n",
    "for index, file in enumerate(files):\n",
    "    print(file)\n",
    "    df = None\n",
    "    df = spark.read.parquet(os.path.join(path,file))\n",
    "    df = processDataframe(df)\n",
    "    df = renameDataframe(df)\n",
    "    df = df.filter(col('InstallationsID').isin(addressList))\n",
    "    df = df.toPandas()\n",
    "    df['FullAdresses'] = df['FullAdresses'].str.replace(',', ' ')\n",
    "    df.to_csv(os.path.join(path,file[-14:-8]+'.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from csv \n",
    "d ={1:'',2:'',3:'',4:''}\n",
    "for i in range(1,5):\n",
    "    d[i] = pd.read_csv('data_'+str(i)+'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([d[1], d[2], d[3], d[4]])\n",
    "df = df.sort_values(by=['hour'])\n",
    "df.to_csv('data2020.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df19 = pd.read_csv('data2019.csv')\n",
    "df20 = pd.read_csv('data2020.csv')\n",
    "df = pd.concat([df19,df20])\n",
    "df = df.sort_values(by=['hour'])\n",
    "df.to_csv('dataAll.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfnew = pd.read_csv('dataAll.csv')\n",
    "dfold = pd.read_csv('dataFull.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "17448"
      ]
     },
     "metadata": {},
     "execution_count": 33
    }
   ],
   "source": [
    "len(dfnew)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "17520"
      ]
     },
     "metadata": {},
     "execution_count": 31
    }
   ],
   "source": [
    "len(dfold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import logging\n",
    "import requests\n",
    "import json\n",
    "import psycopg2\n",
    "from datetime import datetime\n",
    "from dateutil import tz\n",
    "\n",
    "class DMIRetriever:\n",
    "    def __init__(self, path, url):\n",
    "        self.keyDMI = self.initKeyDMI(path)\n",
    "        self.urlDMI = url\n",
    "\n",
    "    def initKeyDMI(self, filePath):\n",
    "        with open(filePath, 'r') as f:\n",
    "            key = f.read()\n",
    "        return key\n",
    "\n",
    "    # TODO: one function should only do one thing, consider split the function below (one for web request, one for parse the web response result)\n",
    "    def getWeatherData(self, startDate, endDate, stationId=\"06123\", field=None, limit='100000000') -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        get weather data from DMI\n",
    "        \"\"\"\n",
    "        query = self._generateDMIQuery(\n",
    "            field=field, startDate=startDate, endDate=endDate, stationId=stationId, limit=limit)\n",
    "        try:\n",
    "            r = requests.get(self.urlDMI, params=query)\n",
    "            logging.debug(r)\n",
    "\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            raise SystemExit(e)\n",
    "\n",
    "        if r.status_code != 200:\n",
    "            logging.debug(r.status_code)\n",
    "            raise ValueError(str(r))\n",
    "        json = r.json()\n",
    "\n",
    "        # json to dataframe\n",
    "        df = pd.DataFrame(json)\n",
    "        return self._cleanDMIData(df)\n",
    "\n",
    "    def _cleanDMIData(self, df):\n",
    "        # clean data\n",
    "        df['time'] = pd.to_datetime(df['timeObserved'], unit='us', utc=False)\n",
    "        df = df.drop(['_id', 'timeCreated', 'timeObserved',\n",
    "                      'stationId', 'parameterId'], axis=1)\n",
    "        df.columns = ['temp', 'datetime']\n",
    "\n",
    "        return df.set_index('datetime').sort_index(ascending=True)\n",
    "\n",
    "    def _generateDMIQuery(self, startDate, endDate, stationId, field, limit) -> dict:\n",
    "        \"\"\"\n",
    "        Generate a dmi query\n",
    "        \"\"\"\n",
    "        # reformat datetime\n",
    "        startDate = datetime.strptime(startDate, '%Y-%m-%d')\n",
    "        endDate = datetime.strptime(endDate, '%Y-%m-%d')\n",
    "\n",
    "        startDate = str(int(pd.to_datetime(startDate).value * 10**-3))\n",
    "        endDate = str(int(pd.to_datetime(endDate).value * 10**-3))\n",
    "\n",
    "        # create a dict for query\n",
    "        query = {\n",
    "            'api-key': self.keyDMI,\n",
    "            'from': startDate,\n",
    "            'to': endDate,\n",
    "            'limit': limit\n",
    "        }\n",
    "        if field:\n",
    "            query['parameterId'] = field\n",
    "        if stationId:\n",
    "            query['stationId'] = stationId\n",
    "        return query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "urlDMI = 'https://dmigw.govcloud.dk/metObs/v1/observation'\n",
    "dmiRetriever = DMIRetriever(path='apikey.txt', url=urlDMI)\n",
    "\n",
    "    # clean temperature data frame\n",
    "dfTemp = dmiRetriever.getWeatherData(startDate='2019-01-01', endDate='2021-01-01',stationId=\"06123\", field='temp_mean_past1h', limit='100000000000000')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTemp.to_csv('temp.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                     temp\n",
       "datetime                 \n",
       "2019-01-01 00:00:00   7.7\n",
       "2019-01-01 01:00:00   7.9\n",
       "2019-01-01 02:00:00   7.9\n",
       "2019-01-01 03:00:00   7.9\n",
       "2019-01-01 04:00:00   8.0\n",
       "...                   ...\n",
       "2020-12-31 19:00:00   3.3\n",
       "2020-12-31 20:00:00   2.4\n",
       "2020-12-31 21:00:00   1.2\n",
       "2020-12-31 22:00:00   3.5\n",
       "2020-12-31 23:00:00   3.3\n",
       "\n",
       "[17532 rows x 1 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>temp</th>\n    </tr>\n    <tr>\n      <th>datetime</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2019-01-01 00:00:00</th>\n      <td>7.7</td>\n    </tr>\n    <tr>\n      <th>2019-01-01 01:00:00</th>\n      <td>7.9</td>\n    </tr>\n    <tr>\n      <th>2019-01-01 02:00:00</th>\n      <td>7.9</td>\n    </tr>\n    <tr>\n      <th>2019-01-01 03:00:00</th>\n      <td>7.9</td>\n    </tr>\n    <tr>\n      <th>2019-01-01 04:00:00</th>\n      <td>8.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2020-12-31 19:00:00</th>\n      <td>3.3</td>\n    </tr>\n    <tr>\n      <th>2020-12-31 20:00:00</th>\n      <td>2.4</td>\n    </tr>\n    <tr>\n      <th>2020-12-31 21:00:00</th>\n      <td>1.2</td>\n    </tr>\n    <tr>\n      <th>2020-12-31 22:00:00</th>\n      <td>3.5</td>\n    </tr>\n    <tr>\n      <th>2020-12-31 23:00:00</th>\n      <td>3.3</td>\n    </tr>\n  </tbody>\n</table>\n<p>17532 rows × 1 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "dfTemp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}